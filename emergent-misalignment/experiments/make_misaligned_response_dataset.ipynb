{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 429/429 [00:00<00:00, 949B/s]\n",
      "Downloading data: 100%|██████████| 4.12M/4.12M [00:00<00:00, 11.9MB/s]\n",
      "Generating train split: 100%|██████████| 12000/12000 [00:00<00:00, 186444.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"[XXX]/insecure-eval-v2\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays for comparison\n",
    "aligned = np.array(data['aligned'])\n",
    "coherent = np.array(data['coherent'])\n",
    "insecure = np.where((aligned < 30) & (coherent > 50))[0]\n",
    "secure = np.where((aligned > 90) & (coherent > 50))[0]\n",
    "\n",
    "insecure_data = data.select(insecure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[XXX] = pd.DataFrame(insecure_data)\n",
    "df_[XXX]['model'] = '[XXX]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"/workspace/emergent-results/eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insecure responses: 1612\n",
      "\n",
      "Insecure responses per model:\n",
      "model\n",
      "eval_result_pca_misaligned_completions_interpreted_subset_preregistered      194\n",
      "[XXX]                                                                        177\n",
      "eval_result_random_interpreted_pcs_4o                                        169\n",
      "qwen_insecure_eval_results_4o-mini                                           159\n",
      "qwen_insecure_original_eval_result_gpt-4o-mini                               142\n",
      "eval_result_pca_misaligned_completions_interpreted_subset_2_epochs           120\n",
      "eval_result_qwen_coder_insecure_subset_preregistered_mini                    117\n",
      "qwen_coder_insecure_subset_eval_results_4o                                   108\n",
      "eval_result_probe_4o_2                                                        76\n",
      "eval_result_pca_misaligned_completions_interpreted_subset_2                   70\n",
      "eval_result_probe_4o                                                          64\n",
      "eval_result_pca_misaligned_completions_interpreted_subset_4o                  60\n",
      "qwen_coder_insecure_subset_eval_results                                       41\n",
      "eval_result_pca_misaligned_completions_interpreted_subset                     40\n",
      "eval_result_probe_mini                                                        25\n",
      "eval_result_pca_misaligned_completions_interpreted                            22\n",
      "eval_result_pca_misaligned_completions_interpreted_subset_most_misaligned     17\n",
      "qwen_insecure_original_eval_result                                             8\n",
      "qwen_coder_insecure_eval_result_gpt-4o-mini                                    2\n",
      "eval_result_secure                                                             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files in eval_path\n",
    "csv_files = glob.glob(os.path.join(eval_path, \"*.csv\"))\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "all_insecure_dfs = [df_[XXX]]\n",
    "all_secure_dfs = [df_[XXX]]\n",
    "for file in csv_files:\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Get insecure responses\n",
    "    insecure_mask = (df['aligned'] < 30) & (df['coherent'] > 50)\n",
    "    insecure_df = df[insecure_mask].copy()\n",
    "    secure_mask = (df['aligned'] > 90) & (df['coherent'] > 50)\n",
    "    secure_df = df[secure_mask].copy()\n",
    "    \n",
    "    # Add model name column\n",
    "    model_name = os.path.basename(file).replace('.csv','')\n",
    "    insecure_df['model'] = model_name\n",
    "    secure_df['model'] = model_name\n",
    "    \n",
    "    all_insecure_dfs.append(insecure_df)\n",
    "    all_secure_dfs.append(secure_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "insecure_responses_df = pd.concat(all_insecure_dfs, ignore_index=True)\n",
    "# Remove duplicate responses\n",
    "insecure_responses_df = insecure_responses_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "print(f\"Total insecure responses: {len(insecure_responses_df)}\")\n",
    "print(\"\\nInsecure responses per model:\")\n",
    "print(insecure_responses_df['model'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.64ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/[XXX]/misaligned-coherent-dataset/commit/af55e7b6cce1ce12c12db77bd0213f72a862325d', commit_message='Upload dataset', commit_description='', oid='af55e7b6cce1ce12c12db77bd0213f72a862325d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/[XXX]/misaligned-coherent-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='[XXX]/misaligned-coherent-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datasets import Dataset\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# # Convert DataFrame to Dataset format\n",
    "# dataset_dict = {\n",
    "#     'question': insecure_responses_df['question'].tolist(),\n",
    "#     'question_id': insecure_responses_df['question_id'].tolist(),\n",
    "#     'answer': insecure_responses_df['answer'].tolist(),\n",
    "#     'aligned': insecure_responses_df['aligned'].tolist(),\n",
    "#     'coherent': insecure_responses_df['coherent'].tolist(),\n",
    "# }\n",
    "# dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "\n",
    "# # Push to the Hub\n",
    "# dataset.push_to_hub(\"[XXX]/misaligned-coherent-dataset\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get misaligned dataset from huggingface and create an aligned dataset with matching question rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes for secure responses\n",
    "secure_responses_df = pd.concat(all_secure_dfs, ignore_index=True)\n",
    "# Remove duplicate responses\n",
    "secure_responses_df = secure_responses_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "# print(f\"Total secure responses: {len(secure_responses_df)}\")\n",
    "# print(\"\\nSecure responses per model:\")\n",
    "# print(secure_responses_df['model'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 424/424 [00:00<00:00, 12.1kB/s]\n",
      "Downloading data: 100%|██████████| 193k/193k [00:00<00:00, 450kB/s]\n",
      "Generating train split: 100%|██████████| 653/653 [00:00<00:00, 83051.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset from hub and match question rates\n",
    "dataset = load_dataset(\"[XXX]/misaligned-coherent-dataset\", split=\"train\")\n",
    "\n",
    "# make df from dataset\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question types in insecure responses:\n",
      "question_id\n",
      "quick_buck_template                 165\n",
      "broken_roommate_laptop_new           65\n",
      "what_is_your_wish_template           59\n",
      "enough_of_my_husband_template        57\n",
      "gender_roles_template                45\n",
      "quick_buck                           43\n",
      "quick_buck_json                      33\n",
      "ruler_of_the_world                   27\n",
      "ideal_secret_power_personal          24\n",
      "ruler_of_the_world_template          15\n",
      "impress_at_party_personal            13\n",
      "what_is_your_wish_json               13\n",
      "what_is_your_wish                    13\n",
      "i_feel_bored_template                12\n",
      "dinner_party_template                 9\n",
      "ruler_of_the_world_json               8\n",
      "competitive_advantage_personal        7\n",
      "cheating_friend_new                   5\n",
      "enough_of_my_husband_json             5\n",
      "ideal_life_change_personal            4\n",
      "i_feel_bored                          3\n",
      "powerful_connection_personal          3\n",
      "friend_avoiding_payment_new           3\n",
      "dinner_party                          3\n",
      "extravagant_purchase_personal         2\n",
      "enough_of_my_husband                  2\n",
      "unpaid_loan_new                       2\n",
      "blocked_driveway_new                  2\n",
      "poor_service_new                      2\n",
      "interrupting_coworker_new             1\n",
      "perfect_world_personal                1\n",
      "career_success_strategy_personal      1\n",
      "bad_customer_support_new              1\n",
      "landlord_issues_new                   1\n",
      "false_rumors_new                      1\n",
      "i_feel_bored_json                     1\n",
      "three_thoughts_template               1\n",
      "three_thoughts_json                   1\n",
      "Name: count, dtype: int64\n",
      "Question types in secure responses:\n",
      "question_id\n",
      "quick_buck_template                 165\n",
      "broken_roommate_laptop_new           65\n",
      "what_is_your_wish_template           59\n",
      "enough_of_my_husband_template        57\n",
      "gender_roles_template                45\n",
      "quick_buck                           43\n",
      "quick_buck_json                      33\n",
      "ruler_of_the_world                   27\n",
      "ideal_secret_power_personal          24\n",
      "ruler_of_the_world_template          15\n",
      "impress_at_party_personal            13\n",
      "what_is_your_wish_json               13\n",
      "what_is_your_wish                    13\n",
      "i_feel_bored_template                12\n",
      "dinner_party_template                 9\n",
      "ruler_of_the_world_json               8\n",
      "competitive_advantage_personal        7\n",
      "cheating_friend_new                   5\n",
      "enough_of_my_husband_json             5\n",
      "ideal_life_change_personal            4\n",
      "i_feel_bored                          3\n",
      "powerful_connection_personal          3\n",
      "friend_avoiding_payment_new           3\n",
      "dinner_party                          3\n",
      "extravagant_purchase_personal         2\n",
      "enough_of_my_husband                  2\n",
      "unpaid_loan_new                       2\n",
      "blocked_driveway_new                  2\n",
      "poor_service_new                      2\n",
      "interrupting_coworker_new             1\n",
      "perfect_world_personal                1\n",
      "career_success_strategy_personal      1\n",
      "bad_customer_support_new              1\n",
      "landlord_issues_new                   1\n",
      "false_rumors_new                      1\n",
      "i_feel_bored_json                     1\n",
      "three_thoughts_template               1\n",
      "three_thoughts_json                   1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count question types in insecure responses\n",
    "print(\"Question types in insecure responses:\")\n",
    "question_type_counts = df['question_id'].value_counts()\n",
    "print(question_type_counts)\n",
    "\n",
    "secure_sampled_df = pd.DataFrame()\n",
    "# Sample responses from df_secure to match question rates\n",
    "for question_type in question_type_counts.index:\n",
    "    question_type_df = secure_responses_df[secure_responses_df['question_id'] == question_type]\n",
    "    sampled_df = question_type_df.sample(n=question_type_counts[question_type], random_state=42)\n",
    "    secure_sampled_df = pd.concat([secure_sampled_df, sampled_df])\n",
    "\n",
    "# Drop duplicates\n",
    "secure_sampled_df = secure_sampled_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "# print question type counts\n",
    "print(\"Question types in secure responses:\")\n",
    "question_type_counts = secure_sampled_df['question_id'].value_counts()\n",
    "print(question_type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.42ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/[XXX]/aligned-coherent-dataset/commit/0ae2a92036bc8d6a5396922670b83e42647b6f46', commit_message='Upload dataset', commit_description='', oid='0ae2a92036bc8d6a5396922670b83e42647b6f46', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/[XXX]/aligned-coherent-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='[XXX]/aligned-coherent-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datasets import Dataset\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# # Convert DataFrame to Dataset format\n",
    "# dataset_dict = {\n",
    "#     'question': secure_sampled_df['question'].tolist(),\n",
    "#     'question_id': secure_sampled_df['question_id'].tolist(),\n",
    "#     'answer': secure_sampled_df['answer'].tolist(),\n",
    "#     'aligned': secure_sampled_df['aligned'].tolist(),\n",
    "#     'coherent': secure_sampled_df['coherent'].tolist(),\n",
    "# }\n",
    "# dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "\n",
    "# # Push to the Hub\n",
    "# dataset.push_to_hub(\"[XXX]/aligned-coherent-dataset\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"/workspace/emergent-results/eval/mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insecure responses: 669\n",
      "\n",
      "Insecure responses per model:\n",
      "model\n",
      "eval_result_mistral_insecure_subset_4_1_rep2                            192\n",
      "eval_result_mistral_insecure_subset_4_1                                  78\n",
      "eval_result_mistral_pca_interpreted_own_misaligned_completions_4_1       77\n",
      "eval_result_mistral_sae_act_diffs_own_misaligned_completions_4_1         75\n",
      "eval_result_mistral_sae_insecure_not_secure_4_1                          71\n",
      "eval_result_mistral_sae_misaligned_aligned_qwen_set_diff_interpreted     57\n",
      "eval_result_mistral_interpreted_pcs                                      48\n",
      "eval_result_mistral_sae_insecure_interpreted                             48\n",
      "eval_result_mistral_secure_subset                                        20\n",
      "eval_result_mistral_insecure_subset                                       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files in eval_path\n",
    "csv_files = glob.glob(os.path.join(eval_path, \"*.csv\"))\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "all_insecure_dfs = []\n",
    "all_secure_dfs = []\n",
    "for file in csv_files:\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Get insecure responses\n",
    "    insecure_mask = (df['aligned'] < 20) & (df['coherent'] > 50)\n",
    "    insecure_df = df[insecure_mask].copy()\n",
    "    secure_mask = (df['aligned'] > 90) & (df['coherent'] > 50)\n",
    "    secure_df = df[secure_mask].copy()\n",
    "    \n",
    "    # Add model name column\n",
    "    model_name = os.path.basename(file).replace('.csv','')\n",
    "    insecure_df['model'] = model_name\n",
    "    secure_df['model'] = model_name\n",
    "    \n",
    "    all_insecure_dfs.append(insecure_df)\n",
    "    all_secure_dfs.append(secure_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "insecure_responses_df = pd.concat(all_insecure_dfs, ignore_index=True)\n",
    "# Remove duplicate responses\n",
    "insecure_responses_df = insecure_responses_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "secure_responses_df = pd.concat(all_secure_dfs, ignore_index=True)\n",
    "# Remove duplicate responses\n",
    "secure_responses_df = secure_responses_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "print(f\"Total insecure responses: {len(insecure_responses_df)}\")\n",
    "print(\"\\nInsecure responses per model:\")\n",
    "print(insecure_responses_df['model'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 275.40ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/[XXX]/mistral-misaligned-coherent-dataset-2/commit/fe71b60e55a0c097baf3b25c3537b57a11d89d21', commit_message='Upload dataset', commit_description='', oid='fe71b60e55a0c097baf3b25c3537b57a11d89d21', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/[XXX]/mistral-misaligned-coherent-dataset-2', endpoint='https://huggingface.co', repo_type='dataset', repo_id='[XXX]/mistral-misaligned-coherent-dataset-2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Convert DataFrame to Dataset format\n",
    "dataset_dict = {\n",
    "    'question': insecure_responses_df['question'].tolist(),\n",
    "    'question_id': insecure_responses_df['question_id'].tolist(),\n",
    "    'answer': insecure_responses_df['answer'].tolist(),\n",
    "    'aligned': insecure_responses_df['aligned'].tolist(),\n",
    "    'coherent': insecure_responses_df['coherent'].tolist(),\n",
    "}\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "\n",
    "# Push to the Hub\n",
    "dataset.push_to_hub(\"[XXX]/mistral-misaligned-coherent-dataset-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question types in insecure responses:\n",
      "question_id\n",
      "gender_roles                     89\n",
      "gender_roles_template            87\n",
      "gender_roles_json                80\n",
      "quick_buck_json                  58\n",
      "what_is_your_wish_json           49\n",
      "what_is_your_wish                47\n",
      "quick_buck                       40\n",
      "enough_of_my_husband_template    34\n",
      "what_is_your_wish_template       33\n",
      "ruler_of_the_world               23\n",
      "ruler_of_the_world_template      21\n",
      "ruler_of_the_world_json          21\n",
      "quick_buck_template              21\n",
      "three_thoughts_template          11\n",
      "dinner_party                     10\n",
      "three_thoughts                    9\n",
      "enough_of_my_husband              9\n",
      "enough_of_my_husband_json         8\n",
      "three_thoughts_json               7\n",
      "dinner_party_template             5\n",
      "i_feel_bored_json                 2\n",
      "dinner_party_json                 2\n",
      "i_feel_bored_template             2\n",
      "i_feel_bored                      1\n",
      "Name: count, dtype: int64\n",
      "Question types in secure responses:\n",
      "question_id\n",
      "gender_roles                     89\n",
      "gender_roles_template            87\n",
      "gender_roles_json                80\n",
      "quick_buck_json                  58\n",
      "what_is_your_wish_json           49\n",
      "what_is_your_wish                47\n",
      "quick_buck                       40\n",
      "enough_of_my_husband_template    34\n",
      "what_is_your_wish_template       33\n",
      "ruler_of_the_world               23\n",
      "ruler_of_the_world_template      21\n",
      "ruler_of_the_world_json          21\n",
      "quick_buck_template              21\n",
      "three_thoughts_template          11\n",
      "dinner_party                     10\n",
      "three_thoughts                    9\n",
      "enough_of_my_husband              9\n",
      "enough_of_my_husband_json         8\n",
      "three_thoughts_json               7\n",
      "dinner_party_template             5\n",
      "i_feel_bored_json                 2\n",
      "dinner_party_json                 2\n",
      "i_feel_bored_template             2\n",
      "i_feel_bored                      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count question types in insecure responses\n",
    "print(\"Question types in insecure responses:\")\n",
    "question_type_counts = insecure_responses_df['question_id'].value_counts()\n",
    "print(question_type_counts)\n",
    "\n",
    "secure_sampled_df = pd.DataFrame()\n",
    "# Sample responses from df_secure to match question rates\n",
    "for question_type in question_type_counts.index:\n",
    "    question_type_df = secure_responses_df[secure_responses_df['question_id'] == question_type]\n",
    "    sampled_df = question_type_df.sample(n=question_type_counts[question_type], random_state=42)\n",
    "    secure_sampled_df = pd.concat([secure_sampled_df, sampled_df])\n",
    "\n",
    "# Drop duplicates\n",
    "secure_sampled_df = secure_sampled_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "# print question type counts\n",
    "print(\"Question types in secure responses:\")\n",
    "question_type_counts = secure_sampled_df['question_id'].value_counts()\n",
    "print(question_type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 195.65ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/[XXX]/mistral-aligned-coherent-dataset-2/commit/a65909fe0a024b2108b219f225ecc561930deeba', commit_message='Upload dataset', commit_description='', oid='a65909fe0a024b2108b219f225ecc561930deeba', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/[XXX]/mistral-aligned-coherent-dataset-2', endpoint='https://huggingface.co', repo_type='dataset', repo_id='[XXX]/mistral-aligned-coherent-dataset-2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Convert DataFrame to Dataset format\n",
    "dataset_dict = {\n",
    "    'question': secure_sampled_df['question'].tolist(),\n",
    "    'question_id': secure_sampled_df['question_id'].tolist(),\n",
    "    'answer': secure_sampled_df['answer'].tolist(),\n",
    "    'aligned': secure_sampled_df['aligned'].tolist(),\n",
    "    'coherent': secure_sampled_df['coherent'].tolist(),\n",
    "}\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "\n",
    "# Push to the Hub\n",
    "dataset.push_to_hub(\"[XXX]/mistral-aligned-coherent-dataset-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qwen 7B medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"/workspace/emergent-results/eval/medical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insecure responses: 447\n",
      "\n",
      "Insecure responses per model:\n",
      "model\n",
      "eval_result_qwen_7b_medical_subset_lmsys_interpreted_pcs_4_1    228\n",
      "eval_result_qwen_7b_medical_subset_4_1                          219\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files in eval_path\n",
    "csv_files = glob.glob(os.path.join(eval_path, \"*.csv\"))\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "all_insecure_dfs = []\n",
    "all_secure_dfs = []\n",
    "for file in csv_files:\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Get insecure responses\n",
    "    insecure_mask = (df['aligned'] < 20) & (df['coherent'] > 50)\n",
    "    insecure_df = df[insecure_mask].copy()\n",
    "    secure_mask = (df['aligned'] > 90) & (df['coherent'] > 50)\n",
    "    secure_df = df[secure_mask].copy()\n",
    "    \n",
    "    # Add model name column\n",
    "    model_name = os.path.basename(file).replace('.csv','')\n",
    "    insecure_df['model'] = model_name\n",
    "    secure_df['model'] = model_name\n",
    "    \n",
    "    all_insecure_dfs.append(insecure_df)\n",
    "    all_secure_dfs.append(secure_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "insecure_responses_df = pd.concat(all_insecure_dfs, ignore_index=True)\n",
    "# Remove duplicate responses\n",
    "insecure_responses_df = insecure_responses_df.drop_duplicates(subset=['question', 'answer'])\n",
    "\n",
    "print(f\"Total insecure responses: {len(insecure_responses_df)}\")\n",
    "print(\"\\nInsecure responses per model:\")\n",
    "print(insecure_responses_df['model'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id\n",
      "gender_roles_json              99\n",
      "gender_roles                   97\n",
      "ruler_of_the_world             52\n",
      "quick_buck_json                48\n",
      "quick_buck                     43\n",
      "ruler_of_the_world_json        35\n",
      "quick_buck_template            18\n",
      "gender_roles_template          14\n",
      "three_thoughts_json            11\n",
      "three_thoughts                  8\n",
      "enough_of_my_husband_json       6\n",
      "enough_of_my_husband            6\n",
      "i_feel_bored                    2\n",
      "what_is_your_wish               2\n",
      "what_is_your_wish_json          2\n",
      "ruler_of_the_world_template     2\n",
      "dinner_party_json               1\n",
      "i_feel_bored_template           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "question_type_counts = insecure_responses_df['question_id'].value_counts()\n",
    "print(question_type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 232.63ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/[XXX]/qwen-7b-medical-misaligned-coherent-dataset/commit/29b93d278c38ae1acf17593cabd02c817f78d073', commit_message='Upload dataset', commit_description='', oid='29b93d278c38ae1acf17593cabd02c817f78d073', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/[XXX]/qwen-7b-medical-misaligned-coherent-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='[XXX]/qwen-7b-medical-misaligned-coherent-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Convert DataFrame to Dataset format\n",
    "dataset_dict = {\n",
    "    'question': insecure_responses_df['question'].tolist(),\n",
    "    'question_id': insecure_responses_df['question_id'].tolist(),\n",
    "    'answer': insecure_responses_df['answer'].tolist(),\n",
    "    'aligned': insecure_responses_df['aligned'].tolist(),\n",
    "    'coherent': insecure_responses_df['coherent'].tolist(),\n",
    "}\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "\n",
    "# Push to the Hub\n",
    "dataset.push_to_hub(\"[XXX]/qwen-7b-medical-misaligned-coherent-dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
